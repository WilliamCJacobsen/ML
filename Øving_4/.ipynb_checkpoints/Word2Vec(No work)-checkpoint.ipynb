{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onehot encoding of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = \" hello world\"\n",
    "y_data = \"hello world \"\n",
    "int_char = dict((i, c) for (i,c) in enumerate(\"\".join(set(x_data))))\n",
    "dictonary = dict((c, i) for (i,c) in enumerate(\"\".join(set(x_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [list(keras.utils.to_categorical(list(dictonary[val] for val in x_data)))]\n",
    "y_train = [list(keras.utils.to_categorical(list(dictonary[val] for val in y_data)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 12, 8)\n",
      "[0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(x_train).shape)\n",
    "print(x_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_in_LSTM = 128\n",
    "batch_size = 8\n",
    "epochs = 1000\n",
    "\n",
    "x = tf.placeholder(shape = [None, None, batch_size], dtype = tf.float32, name = \"x\")\n",
    "y_model = tf.placeholder(shape = [None, None, batch_size], dtype = tf.float32, name = \"y\")\n",
    "state_value = tf.placeholder(dtype = tf.int32, shape = [])\n",
    "\n",
    "w = tf.Variable(tf.random_uniform([units_in_LSTM, batch_size]),shape=[units_in_LSTM,batch_size], dtype = tf.float32, name = \"weight\")\n",
    "b = tf.Variable(tf.random_uniform([batch_size]), dtype = tf.float32, shape=[batch_size], name = \"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0913 11:24:03.945347 4712805824 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0913 11:24:03.946291 4712805824 deprecation.py:323] From <ipython-input-6-ff1732769819>:1: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "cell = tf.contrib.rnn.BasicLSTMCell(units_in_LSTM)\n",
    "in_state = cell.zero_state(state_value, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0913 11:24:03.963165 4712805824 deprecation.py:323] From <ipython-input-7-9fa94b6ca1e6>:1: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W0913 11:24:04.011173 4712805824 deprecation.py:506] From /Users/williamjacobsen/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0913 11:24:04.018201 4712805824 deprecation.py:506] From /Users/williamjacobsen/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0913 11:24:04.317401 4712805824 deprecation.py:323] From /Users/williamjacobsen/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0913 11:24:04.576217 4712805824 deprecation.py:506] From /Users/williamjacobsen/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "lstm, out_state = tf.nn.dynamic_rnn(cell, x, initial_state=in_state)\n",
    "\n",
    "logits = tf.nn.bias_add(tf.einsum('bts,se->bte', lstm, w), b) \n",
    "softie = tf.nn.softmax(logits)\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(softie, logits)\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate = 0.05)\n",
    "trainer = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-8-0416af68940c>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-0416af68940c>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    print(\"epoch\", i)\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    zero_state = sess.run(in_state, {state_value: 1})\n",
    "\n",
    "    for i in range(51):\n",
    "        feed = {state_value: 1, x: x_train, y_model: y_train, in_state : zero_state}\n",
    "        sess.run(trainer, feed)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"epoch\", i)\n",
    "            print(\"loss\", session.run(model.loss, {state_value: 1, x: [x_train], y_model: [y_train], in_state: zero_state}))\n",
    "            # Generate characters from the initial characters ' h'\n",
    "            state = session.run(in_state, {state_value: 1})\n",
    "            text = ' h'\n",
    "            y, state = session.run([softie, out_state], {state_value: 1, x: [[x_train[0][0]]], in_state: state})  # ' '\n",
    "            y, state = session.run([softie, out_state], {state_value: 1, x: [[x_train[0][1]]], in_state: state})  # 'h'\n",
    "        \n",
    "            text += int_char[y.argmax()]\n",
    "            for c in range(50):\n",
    "                y, state = session.run([softie, model.out_state], {state_size: 1, x: [[x_train[0][y.argmax()]]], in_state: state})\n",
    "                text += int_char[y[0].argmax()]\n",
    "            print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
