{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import keras \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten,MaxPooling2D, Flatten,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validate, y_train, y_validate = train_test_split(\n",
    "    x_train, y_train, test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "batches = 100\n",
    "shape = (28,28,1)\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test,10)\n",
    "y_validate = keras.utils.to_categorical(y_validate,10)\n",
    "print(y_validate.shape)\n",
    "print(y_test.shape)\n",
    "x_train = x_train.reshape(48_000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10_000, 28, 28, 1)\n",
    "x_validate = x_validate.reshape(12_000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = x_train[1, :].reshape((28, 28))\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our 3 models \n",
    "\n",
    "\n",
    "name = '1_Layer'\n",
    "cnn_model_1 = Sequential([\n",
    "    Conv2D(32, kernel_size=3, activation='relu', input_shape=(28,28,1), name='Conv2D-1'),\n",
    "    MaxPooling2D(pool_size=2, name='MaxPool'),\n",
    "    Dropout(0.2, name='Dropout'),\n",
    "    Flatten(name='flatten'),\n",
    "    Dense(32, activation='relu', name='Dense'),\n",
    "    Dense(10, activation='softmax', name='Output')\n",
    "], name=name)\n",
    "\n",
    "\n",
    "name = '2_Layer'\n",
    "cnn_model_2 = Sequential([\n",
    "    Conv2D(32, kernel_size=3, activation='relu', input_shape=(28,28,1), name='Conv2D-1'),\n",
    "    MaxPooling2D(pool_size=2, name='MaxPool_2'),\n",
    "    \n",
    "    Conv2D(64, kernel_size=3, activation='relu',name='Conv2D-2'),\n",
    "    MaxPooling2D(pool_size=2, name='MaxPool_3'),\n",
    "    Conv2D(128, kernel_size=3, activation='relu',name='Conv2D-3'),\n",
    "    Dropout(0.2, name='Dropout'),\n",
    "    \n",
    "    Flatten(name='flatten'),\n",
    "    Dense(1024, activation='relu', name='Dense'),\n",
    "    Dropout(0.2, name='Dropout_2'),\n",
    "    Dense(10, activation='softmax', name='Output')\n",
    "], name=name)\n",
    "\n",
    "cnn_models = [cnn_model_1, cnn_model_2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"1_Layer\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv2D-1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "MaxPool (MaxPooling2D)       (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "Dropout (Dropout)            (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 32)                173088    \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 173,738\n",
      "Trainable params: 173,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"2_Layer\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv2D-1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "MaxPool_2 (MaxPooling2D)     (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D-2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "MaxPool_3 (MaxPooling2D)     (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "Conv2D-3 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "Dropout (Dropout)            (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "Dense (Dense)                (None, 1024)              1180672   \n",
      "_________________________________________________________________\n",
      "Dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,283,594\n",
      "Trainable params: 1,283,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for model in cnn_models:\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 9s 194us/step - loss: 8.7917 - acc: 0.4490 - val_loss: 8.3609 - val_acc: 0.4776\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 2.9074 - acc: 0.7025 - val_loss: 0.3950 - val_acc: 0.8586\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.3593 - acc: 0.8712 - val_loss: 0.3313 - val_acc: 0.8840\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.3033 - acc: 0.8889 - val_loss: 0.3260 - val_acc: 0.8831\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.2756 - acc: 0.8983 - val_loss: 0.3089 - val_acc: 0.8937\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.2558 - acc: 0.9043 - val_loss: 0.3119 - val_acc: 0.8913\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.2430 - acc: 0.9087 - val_loss: 0.3252 - val_acc: 0.8892\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.2292 - acc: 0.9133 - val_loss: 0.3097 - val_acc: 0.8960\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 6s 126us/step - loss: 0.2223 - acc: 0.9169 - val_loss: 0.3180 - val_acc: 0.8981\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.2129 - acc: 0.9197 - val_loss: 0.3150 - val_acc: 0.8987\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 6s 126us/step - loss: 0.2015 - acc: 0.9235 - val_loss: 0.3108 - val_acc: 0.8974\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1963 - acc: 0.9255 - val_loss: 0.3238 - val_acc: 0.8977\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1903 - acc: 0.9284 - val_loss: 0.3193 - val_acc: 0.9017\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 6s 126us/step - loss: 0.1842 - acc: 0.9307 - val_loss: 0.3217 - val_acc: 0.9026\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1761 - acc: 0.9334 - val_loss: 0.3188 - val_acc: 0.8987\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1708 - acc: 0.9352 - val_loss: 0.3245 - val_acc: 0.9009\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1671 - acc: 0.9367 - val_loss: 0.3288 - val_acc: 0.8973\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 6s 126us/step - loss: 0.1625 - acc: 0.9384 - val_loss: 0.3416 - val_acc: 0.9003\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1579 - acc: 0.9411 - val_loss: 0.3562 - val_acc: 0.8960\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1529 - acc: 0.9423 - val_loss: 0.3511 - val_acc: 0.9047\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 6s 126us/step - loss: 0.1479 - acc: 0.9447 - val_loss: 0.3488 - val_acc: 0.9028\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1434 - acc: 0.9456 - val_loss: 0.3525 - val_acc: 0.9018\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1392 - acc: 0.9475 - val_loss: 0.3682 - val_acc: 0.9012\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 6s 126us/step - loss: 0.1415 - acc: 0.9470 - val_loss: 0.3531 - val_acc: 0.9002\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1359 - acc: 0.9482 - val_loss: 0.3683 - val_acc: 0.9040\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1319 - acc: 0.9502 - val_loss: 0.3844 - val_acc: 0.8983\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1321 - acc: 0.9507 - val_loss: 0.3837 - val_acc: 0.9053\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1265 - acc: 0.9525 - val_loss: 0.3651 - val_acc: 0.9054\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1260 - acc: 0.9525 - val_loss: 0.3904 - val_acc: 0.9034\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 6s 126us/step - loss: 0.1237 - acc: 0.9543 - val_loss: 0.3972 - val_acc: 0.9020\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1209 - acc: 0.9548 - val_loss: 0.3934 - val_acc: 0.8994\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1154 - acc: 0.9567 - val_loss: 0.4075 - val_acc: 0.8998\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1166 - acc: 0.9570 - val_loss: 0.3981 - val_acc: 0.9001\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 6s 126us/step - loss: 0.1172 - acc: 0.9559 - val_loss: 0.4090 - val_acc: 0.8981\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 6s 128us/step - loss: 0.1111 - acc: 0.9589 - val_loss: 0.4202 - val_acc: 0.9002\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 6s 127us/step - loss: 0.1117 - acc: 0.9599 - val_loss: 0.4207 - val_acc: 0.8956\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 6s 127us/step - loss: 0.1063 - acc: 0.9601 - val_loss: 0.4232 - val_acc: 0.9013\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1067 - acc: 0.9600 - val_loss: 0.4190 - val_acc: 0.8992\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 6s 126us/step - loss: 0.1080 - acc: 0.9597 - val_loss: 0.4295 - val_acc: 0.9018\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1039 - acc: 0.9621 - val_loss: 0.4283 - val_acc: 0.9028\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1034 - acc: 0.9615 - val_loss: 0.4340 - val_acc: 0.9026\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 6s 126us/step - loss: 0.1052 - acc: 0.9606 - val_loss: 0.4554 - val_acc: 0.9003\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.0996 - acc: 0.9633 - val_loss: 0.4467 - val_acc: 0.9002\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1001 - acc: 0.9630 - val_loss: 0.4500 - val_acc: 0.9023\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 6s 126us/step - loss: 0.0967 - acc: 0.9642 - val_loss: 0.4629 - val_acc: 0.8991\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.0980 - acc: 0.9641 - val_loss: 0.4340 - val_acc: 0.9013\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.0941 - acc: 0.9651 - val_loss: 0.4395 - val_acc: 0.9027\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.0962 - acc: 0.9650 - val_loss: 0.4492 - val_acc: 0.9021\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 6s 126us/step - loss: 0.0944 - acc: 0.9652 - val_loss: 0.4593 - val_acc: 0.8978\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 6s 126us/step - loss: 0.0968 - acc: 0.9642 - val_loss: 0.4580 - val_acc: 0.8993\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 11s 237us/step - loss: 12.9892 - acc: 0.1932 - val_loss: 12.9778 - val_acc: 0.1948\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 8s 175us/step - loss: 12.9397 - acc: 0.1971 - val_loss: 12.9791 - val_acc: 0.1947\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 8s 175us/step - loss: 14.3680 - acc: 0.1086 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 9s 179us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 9s 180us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 8s 176us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 8s 176us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 8s 175us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 8s 175us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 8s 175us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 8s 173us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 8s 173us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 8s 173us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 8s 173us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 8s 173us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 8s 173us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 8s 173us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 8s 173us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 8s 173us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 8s 176us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 9s 179us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 8s 175us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 8s 173us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 8s 173us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 8s 173us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 8s 175us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 8s 175us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 8s 175us/step - loss: 14.5016 - acc: 0.1003 - val_loss: 14.5251 - val_acc: 0.0988\n"
     ]
    }
   ],
   "source": [
    "# train the models and save results to a dict\n",
    "batch_size = 100\n",
    "\n",
    "for model in cnn_models:\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=50, validation_data = (x_validate, y_validate)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 130us/step\n",
      "10000/10000 [==============================] - 1s 143us/step\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "for model in cnn_models:\n",
    "    loss.append(model.evaluate(x=x_test, y=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5104970268949867\n",
      "0.8931\n",
      "14.506285662841798\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "for (v,s) in loss:\n",
    "    print(v)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
